{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f460ef64-4c59-457c-8409-c740ffbcf489",
   "metadata": {},
   "source": [
    "# üîç Hello World with LLMs: Personalized Career Advice\n",
    "\n",
    "Compare outputs from popular LLMs by asking each one to suggest 3 career paths based on a user profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c17c0-4f73-4eb0-b955-8d9a65a997a5",
   "metadata": {},
   "source": [
    "## üìÇ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f912d0-78eb-41b7-b129-ce377b472d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai anthropic google-generativeai cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d201b1-27c5-4aba-bc24-d0a58b276723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables stored in a file called .env\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c7057-7152-4634-8f00-56becea6afbb",
   "metadata": {},
   "source": [
    "## üë§ Define the User Profile\n",
    "\n",
    "Instead of hardcoding the same values into the prompt multiple times, we use a Python dictionary to define the user details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbc58b-c7ba-450f-b3fb-0f959f1df2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = {\n",
    "    \"name\": \"Prasath Basuvaraj\",\n",
    "    \"current_role\": \"Software Architect\",\n",
    "    \"experience_years\": 20,\n",
    "    \"skills\": [\"Java\", \"Spring Boot\", \"React\", \"AWS\", \"Microservices\"],\n",
    "    \"goal\": \"career growth and stability\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a78fe1-60d3-4aac-9776-d4a83ca0290f",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Construct the Prompt\n",
    "\n",
    "We then dynamically build a prompt using this profile. This way, every LLM receives the same input in a structured and natural language format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a8bce-74d8-47c7-a76a-075f7f5159f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    f\"Given the following user profile:\\\\n\"\n",
    "    f\"Name: {user_profile['name']}\\\\n\"\n",
    "    f\"Current Role: {user_profile['current_role']}\\\\n\"\n",
    "    f\"Experience: {user_profile['experience_years']} years\\\\n\"\n",
    "    f\"Skills: {', '.join(user_profile['skills'])}\\\\n\"\n",
    "    f\"Goal: {user_profile['goal']}\\\\n\"\n",
    "    \"Suggest 3 career paths this person should consider in 2025 and explain why.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e6a599-87dc-4fbf-88ee-098276fd4aaf",
   "metadata": {},
   "source": [
    "This prompt is then passed to each LLM (cloud-based or local) so we can compare how each model interprets and responds to the same request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba2812-4f22-4513-a574-785b3419ab24",
   "metadata": {},
   "source": [
    "## üî∑ OpenAI GPT-4\n",
    "\n",
    "This section does two things:\n",
    "\n",
    "**Validates your OpenAI API key**\n",
    "Before making any API calls, we check that the key is properly set via environment variables and follows the expected format (sk-proj-...). This helps avoid silent failures or confusing authentication errors.\n",
    "\n",
    "**Sends the prompt to GPT-4**\n",
    "Using the openai Python SDK, we send a structured prompt to the GPT-4 model. The prompt includes the user profile and a request for career path suggestions. The model responds as if it were a helpful career advisor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9b198-6bb7-49f9-80e1-d79f25fed5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the OpenAI Api key\n",
    "if not openai_api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not openai_api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif openai_api_key.strip() != openai_api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good!\")\n",
    "\n",
    "\n",
    "def query_openai(prompt):\n",
    "    client = openai.OpenAI(api_key=openai_api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful career advisor.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Run and display response\n",
    "openai_response = query_openai(prompt_template)\n",
    "print(\"üî∑ OpenAI GPT-4 Response:\")\n",
    "print(openai_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
